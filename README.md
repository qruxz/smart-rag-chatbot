# Role-based PDF QA Chatbot (LangChain + FAISS + Qwen2.5 via Ollama)

An intelligent chatbot powered by a local LLM that can role-play and answer questions based on PDF content.

## Technologies Used
- Python 3.10+
- Streamlit â€“ Interface
- PyMuPDF (fitz) â€“ PDF text extraction
- LangChain â€“ Chunking, Retriever, PromptTemplate
- FAISS â€“ Vector database
- Ollama (Qwen2.5:latest) â€“ Embedding and LLM

## Project Folder Structure
```bash
pdf-chatbot/
â”‚
â”œâ”€â”€ app.py                  # Main application (Streamlit interface)
â”œâ”€â”€ pdf_handler.py          # Extracts text from PDF and chunks it
â”œâ”€â”€ embedder.py             # Embedding + FAISS database operations
â”œâ”€â”€ chatbot.py              # Response generation with Qwen2.5 (via Ollama)
â”œâ”€â”€ prompts.py              # Role-based prompt templates
â”œâ”€â”€ roles.json              # Defines the list of roles
â”œâ”€â”€ vectordb/               # FAISS files are stored here (created when the app runs)
â”œâ”€â”€ data/                   # User-uploaded PDFs (created when the app runs)
â”œâ”€â”€ requirements.txt        # Required libraries
â””â”€â”€ README.md               # Project description
```

## Installation Instructions

1.  **Set up the Python environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # For Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```

2.  **Ensure Ollama is running:**
    Make sure the `qwen2.5:latest` model is running on Ollama. If not installed:
    ```bash
    ollama pull qwen2.5:latest
    ```
    The Ollama service needs to be running in the background (usually started with the `ollama serve` command or the Ollama Desktop application is running). It is not necessary to run the model separately with `ollama run qwen2.5:latest` while the application is running.

    To list installed models:
    ```bash
    ollama list
    ```
    You should see the `qwen2.5:latest` model (or a similar Qwen2.5 tag) in this list.


3.  **Start the application:**
    While in the project's main directory (`pdf-chatbot/`):
    ```bash
    streamlit run app.py
    ```

## Project Niche and Added Value

| Aspect          | Description                                                                 |
|-----------------|-----------------------------------------------------------------------------|
| ğŸ“Œ **Niche**    | An AI capable of role-playing and providing document-based consultancy.     |
| ğŸ§  **LLM Usage**| Local model (Qwen2.5 via Ollama) providing AI privacy and offline operation advantages. |
| ğŸ› ï¸ **RAG Arch.**| Data-driven approach using LangChain + FAISS, differing from classic chatbots. |
| ğŸ’¼ **CV Contrib.**| Combination of LangChain, FAISS, Ollama, PDF parsing, real-world use case. |
